# Air Quality Health Risk Pipeline (Updated)

This project is a **full end-to-end MLOps system** that continuously ingests live airâ€‘quality data, cleans it, retrains forecasting models, serves predictions through an API, monitors operational & ML drift, and automatically triggers alerts and retraining â€” all running inside **Docker** with **cronâ€‘driven automation**.

---

## ğŸš€ System Overview

The pipeline performs the following:

- **Ingest live airâ€‘quality + weather data** from OpenWeatherMap every 5 minutes
- Store raw unmodified responses in an **appendâ€‘only JSONL log**
- Convert raw logs into a **clean Parquet dataset** for training & inference
- Train a **3â€‘hour AQI forecasting model** (LightGBM)
- Serve predictions and explanations via a **FastAPI microservice**
- Generate **LLM explanations** using Ollama (local model)
- Log predictions for **latency tracking, drift detection, and traffic analysis**
- Detect **schema drift**, **data drift**, **model drift**, and **traffic anomalies**
- Perform **autoâ€‘retraining** when drift thresholds are exceeded
- Send **alerts** for failures, drift events, or API performance issues
- Run inside **Docker** and fully orchestrated with **cron jobs**

---

## ğŸ§± Tech Stack

- **Python**, Pandas, NumPy
- **FastAPI** + Uvicorn
- **LightGBM / scikit-learn**
- **MLflow**
- **Docker / Docker Compose**
- **Cron** for automation
- **OpenWeatherMap** (Air Pollution + Weather)
- **Ollama** for LLM explanations
- **Ubuntu (DigitalOcean / local VM)**

---

## ğŸ“ Project Structure

```
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ aq_raw.jsonl            # append-only raw logs
â”‚   â””â”€â”€ aq_clean.parquet        # cleaned feature dataset
â”‚
â”œâ”€â”€ logs/
â”‚   â”œâ”€â”€ predictions.jsonl       # API prediction + latency logs
â”‚   â””â”€â”€ model_performance.jsonl # backfilled error logs (model drift)
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ risk_model.pkl          # trained LightGBM model
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ backfill_model_error.py # hourly backfill for model drift
â”‚   â”œâ”€â”€ run_daily_train.py      # cron: daily retraining
â”‚   â”œâ”€â”€ run_hourly_etl.py       # cron: ETL wrapper
â”‚   â””â”€â”€ quick_forecast.py       # dev-only
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api.py                  # FastAPI application
â”‚   â”œâ”€â”€ ingest_air_quality.py   # live ingestion (raw â†’ JSONL)
â”‚   â”œâ”€â”€ parse_air_quality.py    # ETL to Parquet
â”‚   â”œâ”€â”€ train_risk_model.py     # model training
â”‚   â”œâ”€â”€ llm_explainer.py        # Ollama explanation generation
â”‚   â”œâ”€â”€ risk_labels.py          # AQI â†’ health risk category
â”‚   â”‚
â”‚   â””â”€â”€ monitoring/             # full monitoring suite
â”‚       â”œâ”€â”€ alerts.py
â”‚       â”œâ”€â”€ drift.py
â”‚       â”œâ”€â”€ latency.py
â”‚       â”œâ”€â”€ logging.py
â”‚       â”œâ”€â”€ schema.py
â”‚       â”œâ”€â”€ traffic.py
â”‚       â””â”€â”€ utils.py
â”‚
â”œâ”€â”€ docker-compose.yml          # API + MLflow services
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ–¥ï¸ Running Locally (Development)

### 1. Ingest live data
```bash
python src/ingest_air_quality.py
```

### 2. ETL (raw â†’ clean)
```bash
python src/parse_air_quality.py
```

### 3. Train the forecasting model
```bash
python src/train_risk_model.py
```

### 4. Start the API
```bash
uvicorn src.api:app --reload
```
Docs: http://localhost:8000/docs

### 5. Start MLflow locally (no Docker)
```bash
mlflow ui --backend-store-uri mlruns --host 0.0.0.0 --port 5000
```

### âš ï¸ Local vs Server: LLM Behavior
- **Locally:** Ollama runs normally and provides natural-language explanations.
- **On the server:** If Ollama is not installed (or RAM is limited), the API automatically falls back to a lightweight stringâ€‘only explanation function (no LLM cost, no RAM overhead).

---

## â˜ï¸ Running on the Server (DigitalOcean VM)

On the VM, **you only use `docker-compose`** â€” no building images manually.
Everything is preconfigured: API service, MLflow, volumes.

### Start all services
```bash
docker-compose up -d --build
```

### MLflow UI on the server
Accessible at:
```
http://YOUR_SERVER_IP:5000
```

`docker-compose.yml` manages:
- API service
- MLflow tracking server
- Shared volumes for MLruns, logs, data, models

---

## â± Cron Automation (Production)

Open crontab:
```bash
crontab -e
```

### Ingestion + ETL (every 5 minutes)
```bash
*/5 * * * * docker exec air-quality-api python src/ingest_air_quality.py
*/5 * * * * docker exec air-quality-api python src/parse_air_quality.py
```

### Daily retraining (3 AM)
```bash
0 3 * * * docker exec air-quality-api python src/train_risk_model.py
```

### Model drift backfill (hourly)
```bash
5 * * * * docker exec air-quality-api python scripts/backfill_model_error.py
```

### Simulated API traffic
```bash
*/30 * * * * curl -s http://localhost:8000/forecast/3h/explain > /dev/null
```

### Monitoring suite
```bash
10 * * * * curl -s http://localhost:8000/monitor/schema > /dev/null
11 * * * * curl -s http://localhost:8000/monitor/data_drift > /dev/null
12 * * * * curl -s http://localhost:8000/monitor/model > /dev/null
*  * * * * curl -sf http://localhost:8000/health || curl -H "Content-Type: application/json" -d '{"alert": "API down"}' YOUR_ALERT_ENDPOINT
```

---

## ğŸ” Monitoring Endpoints

### `/monitor/schema`
- Detects schema mismatches between live data and model features

### `/monitor/data_drift`
- Tracks distribution shift using recent prediction logs
- Includes auto-drift alerts and optional auto-retraining

### `/monitor/model`
- Checks degradation over time via RMSE comparison

### `/monitor/traffic`
- Detects spikes/drops in API usage

### `/forecast/3h/explain`
- Returns prediction
- Health label
- Latency
- LLM explanation of AQI risks

---

## ğŸ”” Alerts & Auto-Retraining
The monitoring suite uses the following rules:

- **Schema Drift:** missing/extra columns â†’ alert + fail prediction
- **Data Drift:** moderate/significant drift â†’ alert + optional autoâ€‘retrain
- **Model Drift:** RMSE shift â‰¥ 0.25 â†’ alert + autoâ€‘retrain
- **Latency:** slow prediction â†’ alert
- **Traffic:** large spike/drop â†’ alert
- **API down:** health check fallback curl fires alert

---

## ğŸ”’ Environment Variables (`.env`)

```
OWM_API_KEY=...
OLLAMA_BASE_URL=...
OLLAMA_MODEL=...
ALERT_WEBHOOK_URL=...
```

`.env` **must not be committed**.

---

## ğŸ“ Useful Commands
```bash
git pull origin main
docker-compose up -d --build
docker-compose logs -f
docker logs --tail 50 air-quality-api
docker-compose down
docker-compose restart api
```

---

## ğŸ“Œ Notes
- Everything is designed to run continuously with minimal supervision
- Autoâ€‘drift detection + retraining makes this a productionâ€‘style MLOps system
- Local LLM explanations avoid external API cost
- Docker + cron create a stable, repeatable runtime

---